@prefix core:   <https://w3id.org/polifonia/ontology/core/> .
@prefix fx:     <http://sparql.xyz/facade-x/ns/> .
@prefix geo:    <https://www.w3.org/2003/01/geo/wgs84_pos> .
@prefix meetup: <http://w3id.org/polifonia/pilot/meetups/> .
@prefix mtp:    <http://w3id.org/polifonia/ontology/meetups-ontology#> .
@prefix rdf:    <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs:   <http://www.w3.org/2000/01/rdf-schema#> .
@prefix time:   <http://www.w3.org/2006/time#> .
@prefix xsd:    <http://www.w3.org/2001/XMLSchema#> .
@prefix xyz:    <http://sparql.xyz/facade-x/data/> .

<http://dbpedia.org/resource/Nick_Bostrom>
        rdf:type               core:Person ;
        rdfs:label             "Nick Bostrom" ;
        mtp:hasAbstract        "Nick Bostrom (/ˈbɒstrəm/ BOST-rəm; Swedish: Niklas Boström [ˈnɪ̌kːlas ˈbûːstrœm]; born 10 March 1973) is a Swedish-born philosopher at the University of Oxford known for his work on existential risk, the anthropic principle, human enhancement ethics, superintelligence risks, and the reversal test. In 2011, he founded the Oxford Martin Program on the Impacts of Future Technology, and is the founding director of the Future of Humanity Institute at Oxford University. In 2009 and 2015, he was included in Foreign Policy's Top 100 Global Thinkers list. Bostrom is the author of over 200 publications, and has written two books and co-edited two others. The two books he has authored are Anthropic Bias: Observation Selection Effects in Science and Philosophy (2002) and Superintelligence: Paths, Dangers, Strategies (2014). Superintelligence was a New York Times bestseller, was recommended by Elon Musk and Bill Gates among others, and helped to popularize the term \"superintelligence\". Bostrom believes that superintelligence, which he defines as \"any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest,\" is a potential outcome of advances in artificial intelligence. He views the rise of superintelligence as potentially highly dangerous to humans, but nonetheless rejects the idea that humans are powerless to stop its negative effects. In 2017, he co-signed a list of 23 principles that all A.I. development should follow." ;
        mtp:hasDBPediaEntity   <http://dbpedia.org/resource/Nick_Bostrom> ;
        mtp:hasWikidataEntity  <http://www.wikidata.org/entity/Q460475> ;
        mtp:hasdob             "1973-03-10" ;
        mtp:thumbnail          "http://commons.wikimedia.org/wiki/Special:FilePath/Prof_Nick_Bostrom_324-1.jpg?width=300" .
